{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Carga del archivo business.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_pkl = r\"C:\\Users\\Sofita\\Documents\\Proyecto Final\\Yelp\\\\business.pkl\" \n",
    "data = pd.read_pickle(ruta_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_csv = r\"C:\\Users\\Sofita\\Documents\\Proyecto Final\\Yelp\\\\business.csv\"  \n",
    "data.to_csv(ruta_csv, index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "business = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Carga del archivo 'review.jason'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo CSV guardado en: C:\\\\Users\\\\Sofita\\\\Documents\\\\Proyecto Final\\\\Yelp\\\\reviews_output.csv\n"
     ]
    }
   ],
   "source": [
    "# Leer el archivo JSON en fragmentos\n",
    "chunk_size = 100000  # Ajusta el tamaño del fragmento según tu memoria disponible\n",
    "chunks = pd.read_json(r'C: ... \\\\Yelp\\\\review.json', chunksize=chunk_size, lines=True)\n",
    "\n",
    "# Crear un archivo CSV vacío y escribir los fragmentos\n",
    "csv_file = r'C: ... \\\\Yelp\\\\reviews_output.csv'\n",
    "\n",
    "# Usar 'mode' para evitar sobreescribir el archivo\n",
    "for i, chunk in enumerate(chunks):\n",
    "    if i == 0:\n",
    "        # Escribir el encabezado solo en el primer fragmento\n",
    "        chunk.to_csv(csv_file, mode='w', index=False, header=True)\n",
    "    else:\n",
    "        # Escribir solo las filas para los fragmentos subsiguientes\n",
    "        chunk.to_csv(csv_file, mode='a', index=False, header=False)\n",
    "\n",
    "print(f\"Archivo CSV guardado en: {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = r'C:\\\\ . . . \\\\Yelp\\\\reviews_output.csv'\n",
    "reviews = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_yelp = reviews.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KU_O5udG6zpxOg-VcAEodg</td>\n",
       "      <td>mh_-eMZ6K5RLWhZyISBhwA</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>If you decide to eat here, just be aware it is...</td>\n",
       "      <td>2018-07-07 22:09:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BiTunyQ73aT9WBnpR9DZGw</td>\n",
       "      <td>OyoGAe7OKpv6SyGZT5g77Q</td>\n",
       "      <td>7ATYjTIgM3jUlt4UM3IypQ</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I've taken a lot of spin classes over the year...</td>\n",
       "      <td>2012-01-03 15:28:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saUsX_uimxRlCVr67Z4Jig</td>\n",
       "      <td>8g_iMtfSiwikVnbP2etR0A</td>\n",
       "      <td>YjUWPpI6HXG530lwP-fb2A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Family diner. Had the buffet. Eclectic assortm...</td>\n",
       "      <td>2014-02-05 20:30:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AqPFMleE6RsU23_auESxiA</td>\n",
       "      <td>_7bHUi9Uuf5__HHc_Q8guQ</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n",
       "      <td>2015-01-04 00:01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sx8TMOWLNuJBWer-0pcmoA</td>\n",
       "      <td>bcjbaE6dDog4jkNY91ncLQ</td>\n",
       "      <td>e4Vwtrqf-wpJfwesgvdgxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cute interior and owner (?) gave us tour of up...</td>\n",
       "      <td>2017-01-14 20:54:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "1  BiTunyQ73aT9WBnpR9DZGw  OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ   \n",
       "2  saUsX_uimxRlCVr67Z4Jig  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A   \n",
       "3  AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA   \n",
       "4  Sx8TMOWLNuJBWer-0pcmoA  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      3       0      0     0   \n",
       "1      5       1      0     1   \n",
       "2      3       0      0     0   \n",
       "3      5       1      0     1   \n",
       "4      4       1      0     1   \n",
       "\n",
       "                                                text                 date  \n",
       "0  If you decide to eat here, just be aware it is...  2018-07-07 22:09:11  \n",
       "1  I've taken a lot of spin classes over the year...  2012-01-03 15:28:18  \n",
       "2  Family diner. Had the buffet. Eclectic assortm...  2014-02-05 20:30:30  \n",
       "3  Wow!  Yummy, different,  delicious.   Our favo...  2015-01-04 00:01:03  \n",
       "4  Cute interior and owner (?) gave us tour of up...  2017-01-14 20:54:15  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bussiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_id', 'name', 'address', 'city', 'state', 'postal_code',\n",
       "       'latitude', 'longitude', 'stars', 'review_count', 'is_open',\n",
       "       'attributes', 'categories', 'hours', 'business_id', 'name', 'address',\n",
       "       'city', 'state', 'postal_code', 'latitude', 'longitude', 'stars',\n",
       "       'review_count', 'is_open', 'attributes', 'categories', 'hours'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Función para eliminar columnas duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_columnas_duplicadas(df):\n",
    "    \"\"\"\n",
    "    Elimina columnas duplicadas manteniendo solo la primera aparición.\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): DataFrame que contiene las columnas duplicadas.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame sin columnas duplicadas.\n",
    "    \"\"\"\n",
    "    columnas_repetidas = df.columns[df.columns.duplicated()].unique()\n",
    "    if len(columnas_repetidas) > 0:\n",
    "        print(f\"Columnas duplicadas encontradas: {list(columnas_repetidas)}\")\n",
    "    return df.loc[:, ~df.columns.duplicated()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas duplicadas encontradas: ['business_id', 'name', 'address', 'city', 'state', 'postal_code', 'latitude', 'longitude', 'stars', 'review_count', 'is_open', 'attributes', 'categories', 'hours']\n"
     ]
    }
   ],
   "source": [
    "business = eliminar_columnas_duplicadas(business)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convertir las categorías de la columna 'categories' separadas por comas en listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def transformar_categorias_a_listas(df, columna):\n",
    "    \"\"\"\n",
    "    Transforma los elementos de una columna que contienen categorías separadas por comas\n",
    "    en listas. Maneja valores nulos y tipos no cadena de forma segura.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame que contiene los datos.\n",
    "        columna (str): Nombre de la columna a transformar.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame con la columna transformada.\n",
    "    \"\"\"\n",
    "    if columna not in df.columns:\n",
    "        raise ValueError(f\"La columna '{columna}' no existe en el DataFrame.\")\n",
    "    \n",
    "    def convertir_a_lista(x):\n",
    "        # Si el valor es una cadena válida, dividir por comas y espacios\n",
    "        if isinstance(x, str):\n",
    "            return x.split(', ')\n",
    "        # Si es NaN o None, retornarlo como está\n",
    "        elif pd.isna(x):\n",
    "            return np.nan\n",
    "        # En otros casos, retornar el valor original\n",
    "        return x\n",
    "    \n",
    "    # Aplicar la transformación a toda la columna\n",
    "    df[columna] = df[columna].apply(convertir_a_lista)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "business = transformar_categorias_a_listas(business, 'categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Doctors, Traditional Chinese Medicine, Naturo...\n",
       "1    [Shipping Centers, Local Services, Notaries, M...\n",
       "2    [Department Stores, Shopping, Fashion, Home & ...\n",
       "3    [Restaurants, Food, Bubble Tea, Coffee & Tea, ...\n",
       "4                          [Brewpubs, Breweries, Food]\n",
       "Name: categories, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business['categories'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Filtrar filas donde las listas en la columna 'categories' contienen la palabra 'Restaurant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrar_por_palabras(df, columna, palabras):\n",
    "    \"\"\"\n",
    "    Filtra filas de un DataFrame donde los valores en una columna (listas o strings)\n",
    "    contienen al menos una palabra específica de una lista dada. Luego, reinicia los índices.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): El DataFrame a procesar.\n",
    "        columna (str): El nombre de la columna.\n",
    "        palabras (list): Lista de palabras a buscar.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Un nuevo DataFrame con las filas filtradas y los índices reiniciados.\n",
    "    \"\"\"\n",
    "    if columna not in df.columns:\n",
    "        raise ValueError(f\"La columna '{columna}' no existe en el DataFrame.\")\n",
    "    \n",
    "    if not isinstance(palabras, list):\n",
    "        raise ValueError(\"El argumento 'palabras' debe ser una lista de palabras.\")\n",
    "    \n",
    "    # Filtrar filas\n",
    "    filtrado = df[df[columna].apply(\n",
    "        lambda x: (\n",
    "            isinstance(x, list) and any(palabra in x for palabra in palabras)\n",
    "        ) or (\n",
    "            isinstance(x, str) and x in palabras\n",
    "        )\n",
    "    )]\n",
    "    \n",
    "    # Reiniciar índices\n",
    "    return filtrado.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras = ['Restaurants']\n",
    "\n",
    "business_rest = filtrar_por_palabras(business, 'categories', palabras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_rest.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Realizar el merge conservando todos los datos de business_rest y solo los coincidentes de reviews_yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurantes = business_rest.merge(reviews_yelp, on='business_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurantes.to_csv('restaurantes.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una copia para no afectar el original\n",
    "prueba_restaurantes = restaurantes.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a Dask DataFrame\n",
    "ddf = dd.from_pandas(prueba_restaurantes, npartitions=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las regiones y sus respectivos estados\n",
    "regiones = {\n",
    "    'I-Noreste': ['CT', 'ME', 'MA', 'NH', 'RI', 'VT', 'NJ', 'NY', 'PA'],\n",
    "    'II-Medio Oeste': ['IN', 'IL', 'MI', 'OH', 'WI', 'IA', 'KA', 'MN', 'MO', 'Ne', 'ND', 'SD'],\n",
    "    'III-Sur': ['DE', 'DC', 'FL', 'GA', 'MD', 'NC', 'SC', 'VA', 'WV', 'AL', 'KY', 'MS', 'TN', 'AR', 'LA', 'OK', 'TX'],\n",
    "    'IV-Oeste': ['AZ', 'CO', 'ID', 'NM', 'MT', 'UT', 'NV', 'WY', 'AK', 'CA', 'HI', 'OR', 'WA' ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para filtrar por región\n",
    "def filtrar_por_region(ddf, region):\n",
    "    estados = regiones[region]\n",
    "    return ddf[ddf['state'].isin(estados)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar los datos por cada región y guardar los resultados\n",
    "for region, estados in regiones.items():\n",
    "    # Filtrar y guardar\n",
    "    df_region = filtrar_por_region(ddf, region)\n",
    "    df_region.compute().to_csv(f'restaurantes_{region}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar todos los resultados en un solo DataFrame \n",
    "ddf_combinado = dd.concat([filtrar_por_region(ddf, region) for region in regiones])\n",
    "ddf_combinado.compute().to_csv('restaurantes_todos.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_1 = pd.read_csv('restaurantes_I-Noreste.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_2 = pd.read_csv('restaurantes_II-Medio Oeste.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_3 = pd.read_csv('restaurantes_III-Sur.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_4 = pd.read_csv('restaurantes_IV-Oeste.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consideraciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si se quiere ordenar por región (no probado)\n",
    "\n",
    "Aunque se concatena los DataFrames en el orden en que se filtra, el orden de las filas en el DataFrame resultante no  garantiza que sea exactamente el mismo que el orden en que se agregaron los DataFrames individuales.\n",
    "Si necesitas garantizar que las filas en el DataFrame combinado estén en un orden específico se debes ordenar el DataFrame resultante después de la concatenación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se guardan los datos ordenados por región en un archivo .csv\n",
    "restaurantes_regiones = pd.concat([region_1, region_2, region_3, region_4], ignore_index=True)\n",
    "\n",
    "# Ordenar por región (asumiendo que tienes una columna 'region' en tu DataFrame)\n",
    "restaurantes_regiones = restaurantes_regiones.sort_values(by='region')\n",
    "\n",
    "# Guardar el DataFrame combinado en un archivo CSV\n",
    "restaurantes_regiones.to_csv('restaurantes_regiones.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
